#!/usr/bin/env python3
"""
åŠ å¯†è´§å¸æ–‡ç« åˆ†ç±»å™¨
æ ¹æ®å…³é”®è¯å¯¹æ–‡ç« è¿›è¡Œåˆ†ç±»
"""

import json
import os
import re
import yaml
from datetime import datetime
from collections import defaultdict

class CryptoArticleClassifier:
    def __init__(self):
        # ä»YAMLé…ç½®æ–‡ä»¶åŠ è½½é…ç½®
        self.config = self._load_config()
        self.portfolios = self.config.get('portfolio_projects', [])
        self.categories = self.config.get('classification', {}).get('categories', {})
        self.title_exclusion_keywords = self.config.get('content_filters', {}).get('title_exclusion_keywords', [])

    def _load_config(self):
        """ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            config_file = "crypto_config.yaml"
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
            return config
        except FileNotFoundError:
            print("âŒ æœªæ‰¾åˆ°crypto_config.yamlé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()

    def _get_default_config(self):
        """è¿”å›é»˜è®¤é…ç½®ï¼ˆä½œä¸ºfallbackï¼‰"""
        return {
            'portfolio_projects': [],
            'classification': {'categories': {}},
            'content_filters': {'title_exclusion_keywords': []}
        }
    
    def preprocess_text(self, text):
        """é¢„å¤„ç†æ–‡æœ¬ï¼šè½¬æ¢ä¸ºå°å†™ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦"""
        if not text:
            return ""
        # ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—å’ŒåŸºæœ¬æ ‡ç‚¹
        text = re.sub(r'[^\u4e00-\u9fff\w\s\.\,\!\?\-\+\%\$]', ' ', text)
        return text.lower()
    
    def calculate_score(self, text, keywords, patterns):
        """è®¡ç®—æ–‡æœ¬ä¸å…³é”®è¯å’Œæ¨¡å¼çš„åŒ¹é…åˆ†æ•°"""
        text = self.preprocess_text(text)
        score = 0
        
        # è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°
        for keyword in keywords:
            keyword_lower = keyword.lower()
            # è®¡ç®—å…³é”®è¯å‡ºç°æ¬¡æ•°
            count = len(re.findall(r'\b' + re.escape(keyword_lower) + r'\b', text))
            if count == 0:
                # å¯¹äºä¸­æ–‡å…³é”®è¯ï¼Œä½¿ç”¨ç®€å•çš„åŒ…å«åŒ¹é…
                count = text.count(keyword_lower)
            score += count
        
        # è®¡ç®—æ¨¡å¼åŒ¹é…åˆ†æ•°ï¼ˆæƒé‡æ›´é«˜ï¼‰
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            score += len(matches) * 2  # æ¨¡å¼åŒ¹é…ç»™äºˆ2å€æƒé‡
        
        return score

    def check_portfolio_mention(self, article):
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦æåˆ°äº†IOSGæŠ•èµ„ç»„åˆé¡¹ç›®"""
        title = article.get('title', '')
        
        text = self.preprocess_text(title.lower())
        mentioned_projects = []
        for project in self.portfolios:
            pattern = r'\b' + re.escape(project.lower()) + r'\b'
            if re.search(pattern, text):
                mentioned_projects.append(project)
        
        portfolio = len(mentioned_projects) > 0
        
        return {
            'portfolio': portfolio,
            'mentioned_projects': mentioned_projects,
            'mention_count': len(mentioned_projects)
        }

    def classify_article(self, article):
        """å¯¹å•ç¯‡æ–‡ç« è¿›è¡Œåˆ†ç±»"""
        # åˆå¹¶æ ‡é¢˜å’Œå†…å®¹æ–‡æœ¬
        title = article.get('title', '')
        content = article.get('content_text', '')
        combined_text = f"{title} {content}"
        
        scores = {}
        
        # æ£€æŸ¥portfolioå…³é”®è¯
        portfolio_info = self.check_portfolio_mention(article)
        
        # å¦‚æœæ–‡ç« æåˆ°äº†portfolioé¡¹ç›®ï¼Œç›´æ¥åˆ†ç±»ä¸ºportfolios
        if portfolio_info['portfolio']:
            return {
                'category': 'portfolios',
                'confidence': portfolio_info['mention_count'],
                'scores': {'portfolios': portfolio_info['mention_count']},
                'portfolio': portfolio_info['portfolio'],
                'mentioned_projects': portfolio_info['mentioned_projects'],
                'mention_count': portfolio_info['mention_count']
            }
        
        # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„å¾—åˆ†ï¼ˆæ’é™¤portfolioså’Œå…¶ä»–ï¼‰
        for category, config in self.categories.items():
            if category in ["å…¶ä»–", "portfolios"]:
                continue  # è·³è¿‡å…œåº•åˆ†ç±»å’Œportfoliosåˆ†ç±»
            
            keywords = config['keywords']
            patterns = config.get('patterns', [])
            weight = config['weight']
            score = self.calculate_score(combined_text, keywords, patterns) * weight
            scores[category] = score
        
        # æ‰¾åˆ°æœ€é«˜åˆ†çš„åˆ†ç±»
        if scores and max(scores.values()) > 0:
            best_category = max(scores, key=scores.get)
            confidence = scores[best_category]
        else:
            best_category = "å…¶ä»–"
            confidence = 0
        
        return {
            'category': best_category,
            'confidence': confidence,
            'scores': scores,
            'portfolio': portfolio_info['portfolio'],
            'mentioned_projects': portfolio_info['mentioned_projects'],
            'mention_count': portfolio_info['mention_count']
        }
    
    def classify_articles(self, articles):
        """å¯¹æ‰€æœ‰æ–‡ç« è¿›è¡Œåˆ†ç±»"""
        classified_articles = []
        category_stats = defaultdict(int)
        
        print(f"å¼€å§‹åˆ†ç±» {len(articles)} ç¯‡æ–‡ç« ...")
        
        for i, article in enumerate(articles, 1):
            if i % 100 == 0:
                print(f"å·²å¤„ç† {i}/{len(articles)} ç¯‡æ–‡ç« ")
            
            classification = self.classify_article(article)
            
            # æ·»åŠ åˆ†ç±»ä¿¡æ¯åˆ°æ–‡ç« 
            article_with_class = article.copy()
            article_with_class.update({
                'classification': classification['category'],
                'classification_confidence': classification['confidence'],
                'classification_scores': classification['scores'],
                'portfolio': classification['portfolio'],
                'mentioned_projects': classification['mentioned_projects'],
                'mention_count': classification['mention_count']
            })
            
            classified_articles.append(article_with_class)
            category_stats[classification['category']] += 1
        
        return classified_articles, dict(category_stats)

def main():
    # è¯»å–æœ€æ–°çš„feedsæ–‡ä»¶
    input_file = "latest_feeds.json"
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ {input_file} ä¸å­˜åœ¨")
        print("è¯·å…ˆè¿è¡Œ python fetch_specific_feeds.py")
        return
    except json.JSONDecodeError:
        print(f"âŒ æ–‡ä»¶ {input_file} æ ¼å¼é”™è¯¯")
        return
    
    articles = data.get('articles', [])
    metadata = data.get('metadata', {})
    
    print(f"=== åŠ å¯†è´§å¸æ–‡ç« æ™ºèƒ½åˆ†ç±»å™¨ ===")
    print(f"è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"æ–‡ç« æ€»æ•°: {len(articles)}")
    print(f"æ¥æºç»Ÿè®¡: {metadata.get('feeds_stats', {})}")
    
    # åˆ›å»ºåˆ†ç±»å™¨
    classifier = CryptoArticleClassifier()
    
    # ä½¿ç”¨YAMLé…ç½®ä¸­çš„æ ‡é¢˜å…³é”®è¯ç­›é€‰
    title_keywords = classifier.title_exclusion_keywords
    
    if title_keywords:
        print(f"\n=== åº”ç”¨æ ‡é¢˜å…³é”®è¯è¿‡æ»¤ ===")
        print(f"æ’é™¤å…³é”®è¯: {len(title_keywords)} ä¸ª")
        
        original_count = len(articles)
        # æ ‡é¢˜å…³é”®è¯ç­›é€‰ - åªä¿ç•™æ ‡é¢˜ä¸åŒ…å«ä»»ä½•å…³é”®è¯çš„æ–‡ç« 
        articles = [
            article for article in articles 
            if not any(keyword.lower() in article.get('title', '').lower() for keyword in title_keywords)
        ]
        filtered_count = len(articles)
        
        print(f"åŸå§‹æ–‡ç« æ•°: {original_count}")
        print(f"è¿‡æ»¤åæ–‡ç« æ•°: {filtered_count}")
        print(f"è¿‡æ»¤æ‰: {original_count - filtered_count} ç¯‡ï¼ˆåŒ…å«æ’é™¤å…³é”®è¯ï¼‰")
    
    # è¿›è¡Œåˆ†ç±»
    classified_articles, category_stats = classifier.classify_articles(articles)
    
    
    
    
    # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
    print(f"\n=== åˆ†ç±»ç»“æœç»Ÿè®¡ ===")
    total_classified = len(classified_articles)
    
    for category, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / total_classified) * 100
        print(f"ğŸ“Š {category}: {count} ç¯‡ ({percentage:.1f}%)")
    
    # Portfolioç»Ÿè®¡
    portfolio_articles = [a for a in classified_articles if a.get('portfolio', False)]
    print(f"\nâ­ Portfolioé¡¹ç›®ç›¸å…³æ–‡ç« : {len(portfolio_articles)} ç¯‡ ({len(portfolio_articles)/total_classified*100:.1f}%)")
    
    # æŒ‰åˆ†ç±»ç»Ÿè®¡portfolioæ–‡ç« 
    portfolio_by_category = defaultdict(int)
    for article in portfolio_articles:
        portfolio_by_category[article['classification']] += 1
    
    if portfolio_by_category:
        print("   æŒ‰åˆ†ç±»åˆ†å¸ƒ:")
        for category, count in sorted(portfolio_by_category.items(), key=lambda x: x[1], reverse=True):
            print(f"   - {category}: {count} ç¯‡")
    
    # æŒ‰åˆ†ç±»ç»„ç»‡æ–‡ç« 
    articles_by_category = defaultdict(list)
    for article in classified_articles:
        category = article['classification']
        articles_by_category[category].append(article)
    
    # æ˜¾ç¤ºæ¯ä¸ªåˆ†ç±»çš„ç¤ºä¾‹æ–‡ç« 
    print(f"\n=== åˆ†ç±»ç¤ºä¾‹ï¼ˆæ¯ç±»æ˜¾ç¤ºå‰3ç¯‡ï¼‰ ===")
    for category, articles_list in articles_by_category.items():
        print(f"\nğŸ·ï¸ {category} ({len(articles_list)} ç¯‡):")
        
        # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œæ˜¾ç¤ºå‰3ç¯‡
        sorted_articles = sorted(articles_list, 
                                key=lambda x: x['classification_confidence'], 
                                reverse=True)
        
        for i, article in enumerate(sorted_articles[:3], 1):
            title = article['title']
            source = article['source_feed']
            confidence = article['classification_confidence']
            portfolio_mark = "â­" if article.get('portfolio', False) else ""
            mentioned = article.get('mentioned_projects', [])
            mentioned_str = f" [{', '.join(mentioned[:2])}{'...' if len(mentioned) > 2 else ''}]" if mentioned else ""
            print(f"  {i}. {portfolio_mark}[{source}] {title} (å¾—åˆ†: {confidence}){mentioned_str}")
    
    # ä¿å­˜åˆ†ç±»ç»“æœåˆ°å›ºå®šæ–‡ä»¶
    output_file = "latest_classified.json"
    historical_classified_file = "historical_classified.json"
    
    # å¦‚æœå­˜åœ¨æ—§çš„åˆ†ç±»æ–‡ä»¶ï¼Œå°†å…¶å½’æ¡£åˆ°å†å²æ–‡ä»¶
    if os.path.exists(output_file):
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                old_classified_data = json.load(f)
            
            # è¯»å–æˆ–åˆ›å»ºå†å²åˆ†ç±»æ–‡ä»¶
            historical_classified = {'all_articles': []}
            if os.path.exists(historical_classified_file):
                try:
                    with open(historical_classified_file, 'r', encoding='utf-8') as f:
                        loaded_data = json.load(f)
                    
                    # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
                    if 'all_articles' in loaded_data:
                        # æ–°æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                        historical_classified = loaded_data
                    elif 'articles' in loaded_data:
                        # æ—§æ ¼å¼ï¼Œæå–æ–‡ç« æ•°æ®
                        print("ğŸ”„ è½¬æ¢æ—§æ ¼å¼å†å²åˆ†ç±»æ–‡ä»¶...")
                        historical_classified = {'all_articles': loaded_data['articles']}
                    else:
                        # å…¶ä»–æ ¼å¼ï¼Œåˆ›å»ºæ–°çš„
                        historical_classified = {'all_articles': []}
                        
                except Exception as e:
                    print(f"âš ï¸ å†å²åˆ†ç±»æ–‡ä»¶è¯»å–å¤±è´¥: {e}ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
                    historical_classified = {'all_articles': []}
            
            # å°†æ—§çš„åˆ†ç±»æ•°æ®çš„æ‰€æœ‰æ–‡ç« æ·»åŠ åˆ°å†å²è®°å½•
            old_articles = old_classified_data.get('articles', [])
            if old_articles:
                # ç»™æ¯ä¸ªæ–‡ç« æ·»åŠ åˆ†ç±»æ‰¹æ¬¡æ ‡è¯†
                batch_id = old_classified_data['metadata']['classification_date']
                for article in old_articles:
                    article['classification_batch_id'] = batch_id
                
                # åˆå¹¶åˆ°å†å²æ–‡ç« åˆ—è¡¨
                historical_classified['all_articles'].extend(old_articles)
                print(f"ğŸ“š å·²å°† {len(old_articles)} ç¯‡åˆ†ç±»æ–‡ç« å½’æ¡£åˆ°å†å²æ–‡ä»¶")
            
            # æ›´æ–°å†å²åˆ†ç±»æ–‡ä»¶å…ƒæ•°æ®
            historical_classified['last_updated'] = datetime.now().isoformat()
            historical_classified['total_articles'] = len(historical_classified['all_articles'])
            
            with open(historical_classified_file, 'w', encoding='utf-8') as f:
                json.dump(historical_classified, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“š å†å²åˆ†ç±»æ–‡ä»¶å·²æ›´æ–°ï¼Œå…±åŒ…å« {historical_classified['total_articles']} ç¯‡åˆ†ç±»æ–‡ç« ")
            
        except Exception as e:
            print(f"âš ï¸ å½’æ¡£æ—§åˆ†ç±»æ•°æ®æ—¶å‡ºé”™: {e}")
    
    output_data = {
        'metadata': {
            **metadata,
            'classification_date': datetime.now().isoformat(),
            'total_articles': len(classified_articles),
            'category_stats': category_stats,
            'categories_defined': list(classifier.categories.keys())
        },
        'articles': classified_articles,
        'articles_by_category': dict(articles_by_category)
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ åˆ†ç±»ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # è¾“å‡ºåˆ†ç±»ç»“æœ
    print(f"\nğŸ¯ åˆ†ç±»å®Œæˆï¼å…±å¤„ç† {len(classified_articles)} ç¯‡æ–‡ç« ")

if __name__ == "__main__":
    main()