#!/usr/bin/env python3  
"""
æµ‹è¯•AIæ‰¹é‡è¯­ä¹‰å»é‡åŠŸèƒ½
"""

import os
from ai_filter import AIFundingFilter

def test_ai_batch_semantic_deduplication():
    """æµ‹è¯•AIæ‰¹é‡è¯­ä¹‰å»é‡"""
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼Œæ¨¡æ‹Ÿå·²ç»è¿‡å­—ç¬¦å»é‡çš„æ–‡ç« 
    filtered_results = {
        "project": [
            {
                'title': 'AI å»ä¸­å¿ƒåŒ–æ•°æ®å±‚é¡¹ç›® Poseidon å®Œæˆ 1500 ä¸‡ç¾å…ƒç§å­è½®èèµ„ï¼Œa16z é¢†æŠ•',
                'url': 'https://example1.com',
                'content_text': 'AIå»ä¸­å¿ƒåŒ–æ•°æ®å±‚é¡¹ç›®Poseidonå®Œæˆ1500ä¸‡ç¾å…ƒç§å­è½®èèµ„...'
            },
            {
                'title': 'a16zé¢†æŠ•Poseidon 1500ä¸‡ç¾å…ƒç§å­è½®ï¼Œæ¨åŠ¨AIå»ä¸­å¿ƒåŒ–æ•°æ®å±‚å‘å±•',
                'url': 'https://example2.com', 
                'content_text': 'a16zé¢†æŠ•Poseidonå®Œæˆ1500ä¸‡ç¾å…ƒç§å­è½®èèµ„...'
            },
            {
                'title': 'AIä»£ç†å¹³å°Questflowå®Œæˆ650ä¸‡ç¾å…ƒç§å­è½®èèµ„ï¼ŒCyberFundé¢†æŠ•',
                'url': 'https://example3.com',
                'content_text': 'AIä»£ç†å¹³å°Questflowå®£å¸ƒå®Œæˆ650ä¸‡ç¾å…ƒç§å­è½®èèµ„...'
            }
        ],
        "exchange_wallet": [
            {
                'title': 'FTXå¯»æ±‚å»¶æœŸå›åº”å€ºæƒäººå¼‚è®®ï¼Œ4.7äº¿ç¾å…ƒæµ·å¤–ç´¢èµ”æˆ–è¢«å†»ç»“',
                'url': 'https://example4.com',
                'content_text': 'FTXç”³è¯·å»¶æœŸ...'
            },
            {
                'title': 'FTXç”³è¯·å»¶æœŸå›åº”ï¼Œå› å€ºæƒäººåå¯¹å†»ç»“4.7äº¿ç¾å…ƒæµ·å¤–å€ºæƒ',
                'url': 'https://example5.com',
                'content_text': 'FTXå¯»æ±‚å»¶æœŸ...'
            }
        ],
        "fund": [
            {
                'title': 'ç¨³å®šå¸æ”¯ä»˜æœåŠ¡å¹³å°é²²KUNå®ŒæˆAè½®èèµ„ï¼Œç´¯è®¡èèµ„æ€»é‡‘é¢å·²è¶…5000ä¸‡ç¾å…ƒ',
                'url': 'https://example6.com',
                'content_text': 'é²²KUNå®£å¸ƒå®ŒæˆAè½®èèµ„...'
            },
            {
                'title': 'ç¨³å®šå¸æ”¯ä»˜æœåŠ¡å¹³å°é²² KUN å®Œæˆ A è½®èèµ„ï¼ŒBAI Capital ç­‰å‚æŠ•',
                'url': 'https://example7.com',
                'content_text': 'é²²KUNå®ŒæˆAè½®èèµ„ï¼ŒBAI Capitalå‚æŠ•...'
            }
        ]
    }
    
    print("=== AIæ‰¹é‡è¯­ä¹‰å»é‡æµ‹è¯• ===")
    
    # ç»Ÿè®¡æ€»æ–‡ç« æ•°
    total_articles = sum(len(articles) for articles in filtered_results.values())
    print(f"æµ‹è¯•æ–‡ç« æ€»æ•°: {total_articles}")
    
    # æ˜¾ç¤ºæµ‹è¯•æ•°æ®
    print("\nåŸå§‹æµ‹è¯•æ•°æ®:")
    for category, articles in filtered_results.items():
        print(f"\n{category}:")
        for i, article in enumerate(articles, 1):
            print(f"  {i}. {article['title']}")
    
    # åˆ›å»ºç­›é€‰å™¨ï¼ˆä½¿ç”¨DeepSeekï¼‰
    filter = AIFundingFilter(provider="deepseek")
    
    if not filter.api_key:
        print("âŒ APIå¯†é’¥æœªé…ç½®ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return
    
    # éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½
    semantic_config = filter.config.get('ai_semantic_deduplication', {})
    print(f"é…ç½®åŠ è½½çŠ¶æ€: {'âœ… å·²åŠ è½½' if semantic_config else 'âŒ æœªæ‰¾åˆ°é…ç½®'}")
    if semantic_config:
        settings = semantic_config.get('settings', {})
        print(f"æ‰¹å¤„ç†é™åˆ¶: {settings.get('batch_size_limit', 100)} ç¯‡")
        print(f"æœ€å¤§tokens: {settings.get('max_tokens', 1000)}")
        print(f"æ¸©åº¦è®¾ç½®: {settings.get('temperature', 0)}")
    
    # æ‰§è¡ŒAIæ‰¹é‡è¯­ä¹‰å»é‡
    print(f"\nğŸ¤– æ‰§è¡ŒAIæ‰¹é‡è¯­ä¹‰å»é‡...")
    deduplicated_results, stats = filter.ai_batch_semantic_deduplication(filtered_results)
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\n=== å»é‡ç»“æœ ===")
    print(f"åˆ é™¤æ–‡ç« æ•°: {stats['removed_count']}")
    print(f"é‡å¤ç»„æ•°: {len(stats['duplicate_groups'])}")
    
    # ç»Ÿè®¡å»é‡åçš„æ–‡ç« æ•°
    final_total = sum(len(articles) for articles in deduplicated_results.values())
    print(f"æœ€ç»ˆæ–‡ç« æ•°: {final_total} (åŸå§‹: {total_articles})")
    
    print("\nå»é‡åç»“æœ:")
    for category, articles in deduplicated_results.items():
        if articles:  # åªæ˜¾ç¤ºæœ‰æ–‡ç« çš„åˆ†ç±»
            print(f"\n{category}:")
            for i, article in enumerate(articles, 1):
                print(f"  {i}. {article['title']}")
    
    # éªŒè¯å»é‡æ•ˆæœ
    expected_removals = [
        ("Poseidonèèµ„", 2),  # åº”è¯¥åªä¿ç•™1ç¯‡
        ("FTXå€ºæƒäºº", 2),     # åº”è¯¥åªä¿ç•™1ç¯‡  
        ("é²²KUNèèµ„", 2)      # åº”è¯¥åªä¿ç•™1ç¯‡
    ]
    
    print(f"\n=== å»é‡æ•ˆæœéªŒè¯ ===")
    if stats['removed_count'] >= 3:  # åº”è¯¥åˆ é™¤è‡³å°‘3ç¯‡é‡å¤æ–‡ç« 
        print("âœ… AIæ‰¹é‡è¯­ä¹‰å»é‡æˆåŠŸè¯†åˆ«é‡å¤æ–‡ç« ")
    else:
        print("âš ï¸ AIå¯èƒ½æœªå®Œå…¨è¯†åˆ«é‡å¤æ–‡ç« ")
    
    print(f"åˆ é™¤ç‡: {(stats['removed_count'] / total_articles * 100):.1f}%")

if __name__ == "__main__":
    test_ai_batch_semantic_deduplication()