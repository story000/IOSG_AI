#!/usr/bin/env python3
"""
æµ‹è¯•AIè¯­ä¹‰å»é‡åŠŸèƒ½
"""

import os
from ai_filter import AIFundingFilter

def test_ai_semantic_deduplication():
    """æµ‹è¯•AIè¯­ä¹‰å»é‡"""
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_articles = [
        {
            'title': 'AI å»ä¸­å¿ƒåŒ–æ•°æ®å±‚é¡¹ç›® Poseidon å®Œæˆ 1500 ä¸‡ç¾å…ƒç§å­è½®èèµ„ï¼Œa16z é¢†æŠ•',
            'url': 'https://example1.com',
            'content_text': 'AIå»ä¸­å¿ƒåŒ–æ•°æ®å±‚é¡¹ç›®Poseidonå®Œæˆ1500ä¸‡ç¾å…ƒç§å­è½®èèµ„...'
        },
        {
            'title': 'a16zé¢†æŠ•Poseidon 1500ä¸‡ç¾å…ƒç§å­è½®ï¼Œæ¨åŠ¨AIå»ä¸­å¿ƒåŒ–æ•°æ®å±‚å‘å±•',
            'url': 'https://example2.com', 
            'content_text': 'a16zé¢†æŠ•Poseidonå®Œæˆ1500ä¸‡ç¾å…ƒç§å­è½®èèµ„...'
        },
        {
            'title': 'AIä»£ç†å¹³å°Questflowå®Œæˆ650ä¸‡ç¾å…ƒç§å­è½®èèµ„ï¼ŒCyberFundé¢†æŠ•',
            'url': 'https://example3.com',
            'content_text': 'AIä»£ç†å¹³å°Questflowå®£å¸ƒå®Œæˆ650ä¸‡ç¾å…ƒç§å­è½®èèµ„...'
        },
        {
            'title': 'AIé©±åŠ¨çš„æ²»ç†åè®®Quack AIå®Œæˆ360ä¸‡ç¾å…ƒèèµ„ï¼ŒAnimoca Brandsç­‰å‚æŠ•',
            'url': 'https://example4.com',
            'content_text': 'AIé©±åŠ¨çš„æ²»ç†åè®®Quack AIå®£å¸ƒå®Œæˆ360ä¸‡ç¾å…ƒèèµ„...'
        }
    ]
    
    print("=== AIè¯­ä¹‰å»é‡æµ‹è¯• ===")
    print(f"æµ‹è¯•æ–‡ç« æ•°é‡: {len(test_articles)}")
    
    # åˆ›å»ºç­›é€‰å™¨ï¼ˆä½¿ç”¨DeepSeekï¼‰
    filter = AIFundingFilter(provider="deepseek")
    
    if not filter.api_key:
        print("âŒ APIå¯†é’¥æœªé…ç½®ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return
    
    print("\næµ‹è¯•æ–‡ç« :")
    for i, article in enumerate(test_articles, 1):
        print(f"{i}. {article['title']}")
    
    print("\n=== ä½¿ç”¨AIè¯­ä¹‰å»é‡ ===")
    # æµ‹è¯•AIè¯­ä¹‰å»é‡
    ai_deduplicated, ai_stats = filter.deduplicate_articles_by_title(
        test_articles, "æµ‹è¯•ç±»åˆ«", use_ai=True
    )
    
    print(f"\nAIè¯­ä¹‰å»é‡ç»“æœ:")
    print(f"åŸå§‹: {len(test_articles)} ç¯‡")
    print(f"å»é‡å: {len(ai_deduplicated)} ç¯‡")
    print(f"åˆ é™¤: {ai_stats['removed_count']} ç¯‡")
    print(f"AIæ¯”è¾ƒæ¬¡æ•°: {ai_stats['ai_comparisons']} æ¬¡")
    
    print("\nä¿ç•™çš„æ–‡ç« :")
    for i, article in enumerate(ai_deduplicated, 1):
        print(f"{i}. {article['title']}")
    
    print("\n=== ä½¿ç”¨å­—ç¬¦ç›¸ä¼¼åº¦å»é‡ ===")
    # æµ‹è¯•å­—ç¬¦ç›¸ä¼¼åº¦å»é‡ï¼ˆå¯¹æ¯”ï¼‰
    char_deduplicated, char_stats = filter.deduplicate_articles_by_title(
        test_articles, "æµ‹è¯•ç±»åˆ«", use_ai=False
    )
    
    print(f"\nå­—ç¬¦ç›¸ä¼¼åº¦å»é‡ç»“æœ:")
    print(f"åŸå§‹: {len(test_articles)} ç¯‡")
    print(f"å»é‡å: {len(char_deduplicated)} ç¯‡")
    print(f"åˆ é™¤: {char_stats['removed_count']} ç¯‡")
    
    print("\nä¿ç•™çš„æ–‡ç« :")
    for i, article in enumerate(char_deduplicated, 1):
        print(f"{i}. {article['title']}")
    
    print("\n=== å¯¹æ¯”ç»“æœ ===")
    print(f"AIè¯­ä¹‰å»é‡åˆ é™¤äº† {ai_stats['removed_count']} ç¯‡æ–‡ç« ")
    print(f"å­—ç¬¦ç›¸ä¼¼åº¦å»é‡åˆ é™¤äº† {char_stats['removed_count']} ç¯‡æ–‡ç« ")
    
    if ai_stats['removed_count'] != char_stats['removed_count']:
        print("âœ¨ AIè¯­ä¹‰å»é‡ä¸å­—ç¬¦ç›¸ä¼¼åº¦å»é‡ç»“æœä¸åŒï¼Œå±•ç°äº†AIçš„ä¼˜åŠ¿")
    else:
        print("ğŸ“Š ä¸¤ç§æ–¹æ³•ç»“æœç›¸åŒ")

if __name__ == "__main__":
    test_ai_semantic_deduplication()